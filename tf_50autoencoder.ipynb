{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwMJmOcceuyMyB5UDYbn/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitamingyu/NLP-LLM/blob/main/tf_50autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9xNbKDRt8KFU"
      },
      "outputs": [],
      "source": [
        "# Auto Encoder란 입력 데이터를 압축시켜 압축시킨 데이터로 축소한 후 다시 확장하여 결과 데이터를 입력 데이터와 동일하도록 만드는 일종의 딥 뉴럴 네트워크 모델이다.\n",
        "# Dense 만 사용해서 모델작성\n",
        "# MLIST dataset사용\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_autoencoder(encoding_dim=32, image_shape=(784,)):\n",
        "  # encoder\n",
        "  input_img = Input(shape=image_shape)\n",
        "  encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "\n",
        "  # decoder\n",
        "  decoded = Dense(image_shape[0], activation='sigmoid')(encoded)\n",
        "\n",
        "  # autoencoder model\n",
        "  autoencoder = Model(input_img, decoded)\n",
        "  print(autoencoder.summary())\n",
        "  encoder = Model(input_img, encoded)\n",
        "\n",
        "  # decoder model\n",
        "  encoded_input = Input(shape = (encoding_dim,))\n",
        "  decoder_layer = autoencoder.layers[-1]\n",
        "  decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "  print(decoder.summary())\n",
        "\n",
        "  return autoencoder, encoder, decoder\n",
        "\n",
        "def prepare_data():\n",
        "  (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "  x_train = x_train.astype('float32') / 255.\n",
        "  x_test = x_test.astype('float32') / 255.\n",
        "  x_train = x_train.reshape(len(x_train), np.prod(x_train.shape[1:]))\n",
        "  x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "  print(x_train.shape, ' ', x_test.shape)\n",
        "  return x_train, x_test\n",
        "\n",
        "def display_Images(original, reconstructed, n=10):\n",
        "  plt.figure(figsize=(20,4))\n",
        "  for i in range(n):\n",
        "    # original\n",
        "    ax = plt.subplot(2, n, i +1)\n",
        "    plt.imshow(original[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visibel(False)\n",
        "\n",
        "    # reconstructed\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(original[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visibel(False)\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "BWmwn8h99tZC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  encoding_dim = 32\n",
        "  autoencoder, encoder, decoder = create_autoencoder(encoding_dim)\n",
        "  autoencoder.compile(optimizer = 'adam', loss='binary_crossentropy')\n",
        "\n",
        "  x_train, x_test = prepare_data()\n",
        "\n",
        "  autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test), verbose=2)\n",
        "\n",
        "  encoded_img = encoder.predict(x_test)\n",
        "  decoded_img = decoder.predict(encoded_img)\n",
        "\n",
        "  display_Images(x_test, decoded_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fBZW4MRO9tqY",
        "outputId": "5eeaabf0-5bd7-4ffe-96dd-950a5af2e62e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 784)               25872     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50992 (199.19 KB)\n",
            "Trainable params: 50992 (199.19 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32)]              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 784)               25872     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25872 (101.06 KB)\n",
            "Trainable params: 25872 (101.06 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "(60000, 784)   (10000, 784)\n",
            "Epoch 1/50\n",
            "235/235 - 3s - loss: 0.2759 - val_loss: 0.1856 - 3s/epoch - 14ms/step\n",
            "Epoch 2/50\n",
            "235/235 - 3s - loss: 0.1688 - val_loss: 0.1530 - 3s/epoch - 12ms/step\n",
            "Epoch 3/50\n",
            "235/235 - 3s - loss: 0.1446 - val_loss: 0.1342 - 3s/epoch - 13ms/step\n",
            "Epoch 4/50\n",
            "235/235 - 2s - loss: 0.1288 - val_loss: 0.1212 - 2s/epoch - 10ms/step\n",
            "Epoch 5/50\n",
            "235/235 - 3s - loss: 0.1182 - val_loss: 0.1127 - 3s/epoch - 13ms/step\n",
            "Epoch 6/50\n",
            "235/235 - 3s - loss: 0.1108 - val_loss: 0.1064 - 3s/epoch - 11ms/step\n",
            "Epoch 7/50\n",
            "235/235 - 4s - loss: 0.1054 - val_loss: 0.1020 - 4s/epoch - 18ms/step\n",
            "Epoch 8/50\n",
            "235/235 - 3s - loss: 0.1016 - val_loss: 0.0988 - 3s/epoch - 13ms/step\n",
            "Epoch 9/50\n",
            "235/235 - 2s - loss: 0.0989 - val_loss: 0.0969 - 2s/epoch - 9ms/step\n",
            "Epoch 10/50\n",
            "235/235 - 2s - loss: 0.0971 - val_loss: 0.0952 - 2s/epoch - 10ms/step\n",
            "Epoch 11/50\n",
            "235/235 - 2s - loss: 0.0959 - val_loss: 0.0943 - 2s/epoch - 10ms/step\n",
            "Epoch 12/50\n",
            "235/235 - 2s - loss: 0.0951 - val_loss: 0.0936 - 2s/epoch - 9ms/step\n",
            "Epoch 13/50\n",
            "235/235 - 3s - loss: 0.0946 - val_loss: 0.0932 - 3s/epoch - 14ms/step\n",
            "Epoch 14/50\n",
            "235/235 - 2s - loss: 0.0943 - val_loss: 0.0929 - 2s/epoch - 10ms/step\n",
            "Epoch 15/50\n",
            "235/235 - 2s - loss: 0.0941 - val_loss: 0.0928 - 2s/epoch - 10ms/step\n",
            "Epoch 16/50\n",
            "235/235 - 2s - loss: 0.0939 - val_loss: 0.0926 - 2s/epoch - 10ms/step\n",
            "Epoch 17/50\n",
            "235/235 - 2s - loss: 0.0937 - val_loss: 0.0925 - 2s/epoch - 9ms/step\n",
            "Epoch 18/50\n",
            "235/235 - 3s - loss: 0.0936 - val_loss: 0.0924 - 3s/epoch - 12ms/step\n",
            "Epoch 19/50\n",
            "235/235 - 3s - loss: 0.0935 - val_loss: 0.0923 - 3s/epoch - 13ms/step\n",
            "Epoch 20/50\n",
            "235/235 - 2s - loss: 0.0934 - val_loss: 0.0922 - 2s/epoch - 10ms/step\n",
            "Epoch 21/50\n",
            "235/235 - 2s - loss: 0.0934 - val_loss: 0.0923 - 2s/epoch - 10ms/step\n",
            "Epoch 22/50\n",
            "235/235 - 2s - loss: 0.0933 - val_loss: 0.0921 - 2s/epoch - 9ms/step\n",
            "Epoch 23/50\n",
            "235/235 - 2s - loss: 0.0933 - val_loss: 0.0921 - 2s/epoch - 9ms/step\n",
            "Epoch 24/50\n",
            "235/235 - 4s - loss: 0.0932 - val_loss: 0.0921 - 4s/epoch - 15ms/step\n",
            "Epoch 25/50\n",
            "235/235 - 2s - loss: 0.0932 - val_loss: 0.0919 - 2s/epoch - 10ms/step\n",
            "Epoch 26/50\n",
            "235/235 - 2s - loss: 0.0932 - val_loss: 0.0920 - 2s/epoch - 10ms/step\n",
            "Epoch 27/50\n",
            "235/235 - 2s - loss: 0.0931 - val_loss: 0.0919 - 2s/epoch - 10ms/step\n",
            "Epoch 28/50\n",
            "235/235 - 2s - loss: 0.0931 - val_loss: 0.0921 - 2s/epoch - 10ms/step\n",
            "Epoch 29/50\n",
            "235/235 - 3s - loss: 0.0931 - val_loss: 0.0919 - 3s/epoch - 12ms/step\n",
            "Epoch 30/50\n",
            "235/235 - 3s - loss: 0.0930 - val_loss: 0.0919 - 3s/epoch - 12ms/step\n",
            "Epoch 31/50\n",
            "235/235 - 2s - loss: 0.0930 - val_loss: 0.0919 - 2s/epoch - 9ms/step\n",
            "Epoch 32/50\n",
            "235/235 - 2s - loss: 0.0930 - val_loss: 0.0918 - 2s/epoch - 10ms/step\n",
            "Epoch 33/50\n",
            "235/235 - 2s - loss: 0.0930 - val_loss: 0.0919 - 2s/epoch - 10ms/step\n",
            "Epoch 34/50\n",
            "235/235 - 2s - loss: 0.0930 - val_loss: 0.0918 - 2s/epoch - 10ms/step\n",
            "Epoch 35/50\n",
            "235/235 - 3s - loss: 0.0930 - val_loss: 0.0919 - 3s/epoch - 14ms/step\n",
            "Epoch 36/50\n",
            "235/235 - 2s - loss: 0.0929 - val_loss: 0.0919 - 2s/epoch - 10ms/step\n",
            "Epoch 37/50\n",
            "235/235 - 2s - loss: 0.0929 - val_loss: 0.0918 - 2s/epoch - 10ms/step\n",
            "Epoch 38/50\n",
            "235/235 - 2s - loss: 0.0929 - val_loss: 0.0918 - 2s/epoch - 9ms/step\n",
            "Epoch 39/50\n",
            "235/235 - 2s - loss: 0.0929 - val_loss: 0.0918 - 2s/epoch - 9ms/step\n",
            "Epoch 40/50\n",
            "235/235 - 3s - loss: 0.0929 - val_loss: 0.0918 - 3s/epoch - 12ms/step\n",
            "Epoch 41/50\n",
            "235/235 - 3s - loss: 0.0929 - val_loss: 0.0918 - 3s/epoch - 13ms/step\n",
            "Epoch 42/50\n",
            "235/235 - 2s - loss: 0.0928 - val_loss: 0.0918 - 2s/epoch - 10ms/step\n",
            "Epoch 43/50\n",
            "235/235 - 2s - loss: 0.0928 - val_loss: 0.0918 - 2s/epoch - 9ms/step\n",
            "Epoch 44/50\n",
            "235/235 - 2s - loss: 0.0928 - val_loss: 0.0917 - 2s/epoch - 9ms/step\n",
            "Epoch 45/50\n",
            "235/235 - 2s - loss: 0.0928 - val_loss: 0.0917 - 2s/epoch - 9ms/step\n",
            "Epoch 46/50\n",
            "235/235 - 3s - loss: 0.0928 - val_loss: 0.0917 - 3s/epoch - 14ms/step\n",
            "Epoch 47/50\n",
            "235/235 - 2s - loss: 0.0928 - val_loss: 0.0917 - 2s/epoch - 10ms/step\n",
            "Epoch 48/50\n",
            "235/235 - 3s - loss: 0.0928 - val_loss: 0.0917 - 3s/epoch - 11ms/step\n",
            "Epoch 49/50\n",
            "235/235 - 3s - loss: 0.0928 - val_loss: 0.0917 - 3s/epoch - 12ms/step\n",
            "Epoch 50/50\n",
            "235/235 - 4s - loss: 0.0928 - val_loss: 0.0917 - 4s/epoch - 16ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6e981fd17dc3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mdecoded_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mdisplay_Images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-286dcfcdeaa2>\u001b[0m in \u001b[0;36mdisplay_Images\u001b[0;34m(original, reconstructed, n)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visibel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# reconstructed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'YAxis' object has no attribute 'set_visibel'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6ljCFgY9vCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}